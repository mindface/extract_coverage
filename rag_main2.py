import os
from pathlib import Path
from llama_index.core import VectorStoreIndex
from llama_index.core.settings import Settings
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.llms.ollama import Ollama
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.core.node_parser import SimpleNodeParser
from llama_index.core.schema import Document
from llama_index.core import get_response_synthesizer
from llama_index.core.postprocessor import SimilarityPostprocessor
from llama_index.core.prompts import PromptTemplate
from llama_index.core.storage import StorageContext
import chromadb
import sqlite3
from datetime import datetime, timedelta

# === è¨­å®š ===
OLLAMA_MODEL = "llama3.1:8b"
CHROMA_DIR = "chroma_store"
HISTORY_DB = "./docs/history.db"
CHUNK_SIZE = 256
CHUNK_OVERLAP = 20

# LLM / Embedding è¨­å®š
llm = Ollama(model=OLLAMA_MODEL, request_timeout=120.0)
embed_model = OllamaEmbedding(model_name=OLLAMA_MODEL, request_timeout=60.0)
Settings.llm = llm
Settings.embed_model = embed_model

# Chroma ã®è¨­å®š
chroma_client = chromadb.PersistentClient(path=CHROMA_DIR)
chroma_collection = chroma_client.get_or_create_collection("rag_docs")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
qa_template = PromptTemplate(
    """\
æ–‡è„ˆæƒ…å ±ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:
---------------------
{context_str}
---------------------

ã“ã®æ–‡è„ˆæƒ…å ±ã‚’ã‚‚ã¨ã«ã€ä»¥ä¸‹ã®è³ªå•ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
è³ªå•: {query_str}

å›ç­”: """
)

# å±¥æ­´ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŠ½å‡º
def get_history_documents(path=HISTORY_DB, days=7, limit=50):
    chrome_epoch = datetime(1601, 1, 1)
    cutoff = datetime.utcnow() - timedelta(days=days)
    cutoff_microseconds = int((cutoff - chrome_epoch).total_seconds() * 1_000_000)

    conn = sqlite3.connect(path)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT title, url, visit_time FROM history
        ORDER BY visit_time DESC LIMIT ?
    """, (limit,))
    docs = [
        Document(text=f"{title or '(no title)'}\n{url}")
        for title, url, _ in cursor.fetchall()
    ]
    conn.close()
    return docs

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæº–å‚™ â†’ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
docs = get_history_documents()
if not docs:
    print("å±¥æ­´ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
    exit()

parser = SimpleNodeParser.from_defaults(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
nodes = parser.get_nodes_from_documents(docs)
index = VectorStoreIndex(nodes, storage_context=storage_context)

# ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
query_engine = index.as_query_engine(
    similarity_top_k=10,
    response_synthesizer=get_response_synthesizer(
        response_mode="tree_summarize",
        text_qa_template=qa_template,
    ),
    # node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],
)

# å¯¾è©±
while True:
    query = input("\nğŸ” è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆqã§çµ‚äº†ï¼‰: ")
    if query.strip().lower() == "q":
        break
    print("å›ç­”ç”Ÿæˆä¸­...")
    response = query_engine.query(query)
    print(f"\nğŸ§  å›ç­”:\n{response}")
